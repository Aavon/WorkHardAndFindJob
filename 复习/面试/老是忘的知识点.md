# 老是忘的知识点

## 1.进程间通信的方式

进程间通信主要有以下几种方式：
* 管道：
	* 只支持半双工通信
	* 只能在父子进程或者兄弟进程间使用
* FIFO：去除了管道只能在父子进程中使用的限制，常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据
* 消息队列：相比FIFO具有以下优点
	* 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
	* 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
	* 进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收
* 信号量：是一个计数器，用于为多个进程提供对共享数据对象的访问
* 共享存储：
	* 允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC
	* 需要使用信号量来同步对共享存储的访问
	* 多个进程可以将同一个文件映射到他们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段
* 套接字：与其它通信机制不同的是，它可用于不同机器间的进程通信。

### 进程和线程的区别

* 进程是操作系统分配资源的最小单位，线程是程序执行的最小单位；
* 进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据的，使用相同的地址空间，因此 CPU 切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。
* 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要管道、FIFO、消息队列、信号量、共享存储、套接字的方式进行。



## 2.TCP 中 time_wait 和 close_wait 产生的原因

![TCP 状态转换图1](https://uploader.shimo.im/f/OLBLXAmPKYeOjD2l.png!thumbnail)

![TCP 状态转换图2](https://uploader.shimo.im/f/QrRaIKELGM84hOb4.png!thumbnail)

**time_wait 产生的原因：**
客户机在发起关闭连接后的第四次挥手时，客户机收到服务器发送的 FIN 报文段，然后客户机发出 ACK 并进入 time_wait 状态。在这个状态下，如果客户机发出的 ACK 丢失，那么由于 TCP 的重传机制，服务器会重发 FIN，此时客户机还能重发 ACK。如果没有这个状态，那么客户机直接释放连接后，如果发出的 ACK 丢失，等到客户机重新受到服务器发出的 FIN 时，就会发出 RST 包使得服务器以为有错误发生。在进入 time_wait 状态后，客户机仍要经过 2 个MSL值才能释放连接。

**close_wait 产生的原因：**
服务器收到了客户机发出的 FIN，但是还没有服务器还没有发出自己这边的 FIN，此时服务器就会进入 close_wait 的状态。可能的原因是服务器正在忙于读或者写，或者在准备关闭前的事情。



## 3.HTTP 协议与 HTTPS 协议的区别？

* (1) https 协议需要到 ca 申请证书，一般免费证书较少，因而需要一定费用。
* (2) http 是超文本传输协议，信息是明文传输，https 则是具有安全性的 ssl 或者 tls 加密传输协议。
* (3) http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。
* (4) http 的连接很简单，是无状态的；HTTPS 协议是由 SSL + HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 http 协议安全。



## 4.volatile 导致的总线嗅探和总线风暴问题

总线嗅探和总线风暴问题只会出现在**多核处理器**上

**总线嗅探**：
如果对声明了 volatile 的变量进行写操作，JVM 就会想处理器发送一条 lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存**缓存一致性协议**，**每个处理器通过嗅探在总线上传播的数据来检查自己的缓存值是不是过期了，如果处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置无效状态**，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据库读到处理器缓存中。

**总线风暴**：
volatile 修饰的关键字不断刷新导致**每个处理器不断地去进行总线嗅探，太频繁的总线嗅探操作导致总线带宽达到峰值**。



## 5.redis 和 memcache 的区别

* **redis 支持更丰富的数据类型（支持更复杂的应用场景）**：Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。memcache 支持简单的数据类型，String。
* **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中**。
* **集群模式**：memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.
* **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型**。

![redis 和 memcache 的区别](https://uploader.shimo.im/f/IFu5Xk1tsON0QkK2.jpeg!thumbnail)



## 6.redis 缓存雪崩和缓存穿透的问题

首先，要了解什么是缓存雪崩和缓存穿透。

**缓存雪崩**：
**缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。**

**解决方案**：
* 保证缓存层服务的高可用性，比如主从、分布式缓存、尽快补上机器
* 在缓存失效后通过加锁或者队列的方式来限流并降级，防止数据库崩坏
* 将持久化保存的数据快速恢复，并在大并发访问前对数据进行预热，以及设置不同的过期时间

**缓存穿透**：
缓存穿透说简单点就是**大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层**。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

**解决方案**：
* 布隆过滤器，用来判断请求的 key 是否有可能存在，不存在就直接过滤
* 缓存空值。当 key 不存在给他设定一个空值



## 7.redis 并发竞争问题

我们要知道，redis 本身是单线程的，因此 redis 本身不会有并发问题。但是多个进行同时去 set 的时候，会出现顺序问题，比如多客户端同时并发写一个 key，一个 key 的值是1，本来按顺序修改为 2,3,4，最后是 4，但是顺序变成了 4,3,2，最后变成了 2。

在这种场景下，有两种方案：
* （1）分布式锁
* （2）消息队列将并行操作串行化



## 8.数据库和缓存的数据一致性问题

**解决方案**:
当存在更新操作时，先删除缓存，再更新数据库，再更新缓存，并且将请求串行化。但是这样并发效率就降低了



## 9.可达性分析中可用作 GC Roots 的对象有哪些？

在Java语言里，固定可作为GC Roots对象的包括如下几种：

* 在虚拟机栈（栈帧中的本地变量表）中引用的对象，譬如各个线程中被调用的方法堆栈中使用到的参数、局部变量、临时变量等
* 在方法区中类静态属性引用的对象，譬如 Java 类的引用类型静态变量
* 在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用
* 在本地方法栈中 JNI（即通常所说的 Native 方法）引用的对象
* Java 虚拟机内部的引用，如基本数据类型对应的 Class 对象，一些常驻的异常对象（比如 NullPointException、OutOfMemoryError）等，还有系统类加载器
* 所有被同步锁（Synchronized 关键字）持有的对象
* 反映 Java 虚拟机内部情况的 JMXBean、JVMTI 中注册的回调、本地代码缓存等



## 10. 什么是 BIO、NIO、AIO？

BIO：同步阻塞，一个线程一个连接

NIO：同步非阻塞，一个线程多个连接，核心是：缓冲区、通道、选择器

AIO：异步非阻塞



## 11. 消息队列如何做到有序消费（优化分布式下的并发问题）

通过设置消息的一个修改时间，以及 redis 中的一个上次消费的时间戳来判断。

或者可以使用消息的 message_id，然后配合 redis 中的上次消费的 id 来判断。

解决并发问题的话，还需要用到分布式锁



## 12. 长连接的实现方式

在日常项目中，大多的时候我们用的是短连接，一个请求过来，一个线程处理完该请求，线程被线程池回收，这个请求就关闭了。虽然这能满足很大部分的需求，但是也有些问题，比如说：如果客户端发的请求比较多，比较频繁,服务端就会忙于建立连接处理请求，由于服务端的线程数也有限，并发比较大的话有可能会造成服务端的崩溃。那有没有一种办法使连接少一些，让一个线程可以处理多个连接？长连接的出现就是为了解决上面的问题。

在 Java 中实现长连接，即在 Socket 使用完毕后不进行关闭，而是使用一个子线程每隔一段时间发送心跳包给服务器。



## 13. volatile 关键字

可见性、有序性

可见性涉及到 JMM，通过缓存一致性协议使得其他高速缓存中的副本失效。遇到经常修改的值使用 volatile 时，可能会引起总线风暴。

有序性即编译器在遇到 volatile 时，保证上下指令不被重排，起到了内存屏障的作用。

但是 volatile 不能保证原子性，因此在多线程下会出现问题。

[博客](https://www.cnblogs.com/dolphin0520/p/3920373.html)



## 14. ThreadLocal 

[博客](https://www.cnblogs.com/xzwblog/p/7227509.html)



## 15. 接口和抽象类的区别

首先，这两者的语法区别如下：

| 参数           | 抽象类                                                       | 接口                                                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 声明           | 抽象类使用 abstract 关键字声明                               | 接口使用 interface 关键字声明                                |
| 实现           | 子类使用 extends 关键字来继承抽象类。如果子类不是抽象类的话，他需要提供抽象类中所有声明的方法的实现 | 子类使用 implements关键字来实现接口。它需要提供接口中所有声明的方法的实现 |
| 构造器         | 抽象类可以有构造器                                           | 接口没有构造器                                               |
| 访问修饰符     | 抽象类中的方法可以是任意访问修饰符                           | 接口方法默认修饰符是 public，并且不允许定义为 private 或者 protected |
| 多继承（实现） | 一个类最多只能继承一个抽象类                                 | 一个类可以实现多个接口                                       |
| 字段声明       | 抽象类的字段声明可以是任意的                                 | 接口的字段默认都是 static 和 final                           |
| 设计           | 抽象类是模板类设计                                           | 接口是契约式设计                                             |
| 作用           | 抽象类被继承时体现的是 is-a 关系                             | 接口被实现时体现的是 can-do 关系                             |

接口和抽象类各有优缺点，在接口和抽象类的选择上，必须遵守这样的原则：
* 行为模型应该总是通过接口而不是抽象类定义，所以通常是优先选用接口，尽量少用抽象类；
* 选择抽象类的时候通常是如下情况：需要定义子类的行为，又要为子类提供通用的功能

备注：Java 8 中接口引入默认方法和静态方法，以此来减少抽象类和接口之间的差异。现在，我们可以为接口提供默认实现的方法了，并且不用强制子类来实现它。



## 16. http 和 https 的过程

http 的过程：

* 浏览器和服务器建立 TCP 连接（默认端口 80）
* 浏览器发出 http 请求
* 服务器通过 http 相应将文件发送给浏览器
* tcp 连接释放
* 浏览器解析文件并展示给用户

https 的过程：

* 浏览器向服务器发起请求，连接服务器 443 端口，同时将自己支持的加密算法发给服务器
* 服务器会检查浏览器发来的加密算法自己是否支持，不支持就断开链接，否则将选好的算法和证书发个客户端
* 客户端验证证书有效性，并生成对称秘钥，利用公钥进行加密后发送给服务端
* 服务端收到对称秘钥，接下来就开始利用对称秘钥进行对称加密进行通信

## 17. 死锁

**死锁的条件：**

* 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；
* 请求与保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源
* 非剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放
* 循环等待条件：系统中若干进程组成环路，环路中每个进程都在等待相邻进程占用的资源

**解决方法：**破坏死锁的任意一条件

* 资源一次性分配，从而剥夺请求和保持条件
* 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件
* 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件

